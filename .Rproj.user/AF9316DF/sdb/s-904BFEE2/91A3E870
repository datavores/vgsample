{
    "contents" : "---\ntitle: \"Giantbomb Data Cleaning\"\nauthor: \"Brian Waismeyer\"\ndate: \"`r Sys.Date()`\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{Giantbomb Data Cleaning}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\nThis document covers the details of how the API-retrieved Giantbomb records are\nprocessed for merging. It starts by loading the raw API data (see the Giantbomb\nData Scraping document for details) and concludes with Giantbomb records in the\ndesired structure for merging.\n\nThe Giantbomb data were retrieved on 2/3/2016 and consist of all the game \nrecords available on the Giantbomb API at that time.\n\n**Note**: Carefully observe the globals (e.g.,`id_variations_from_scratch`) in \nthe opening code below. The major processes underlying the identification of \nvalue mispellings/variations in the game records (especially the game titles) \nare _very_ lengthy (up to several hours) and resolving identified assocations is\noften best informed by some additional manual interaction with the data to \nassess if new auto-resolve rules are appropriate. Unless you are very certain \nthe data need to be re-processed, it is suggested that you keep globals at their\ndefaults and work with the intermediate data products loaded into the workspace.\n\n**Note**: If run, this document assumes certain resources (e.g., the Giantbomb\nraw data .Rds) are available in the local working directory.\n\n## Prepare the Workspace\n\nWe start by loading supporting packages and setting desired global options.\n\n```{r prepare_workspace}\n# Load supporting packages.\nlibrary(dplyr)          # Data manipulation.\nlibrary(lubridate)      # Date manipulation.\nlibrary(stringr)        # String manipulation.\nlibrary(stringdist)     # Fuzzy string matching.\n\n# Set document globals.\nrun_from_scratch <- FALSE\n```\n\nTo keep the later portions of the document concise, we also define our custom\nhelper functions here. Functions are presented in the order they are called.\n\n```{r define_helper_functions}\nsource(\"./cleaning_functions.R\")\n```\n\nFinally, we load the raw Giantbomb data.\n\n```{r load_raw_data}\n# Load the raw results of the Giantbomb scraping script. This is a list of game\n# dataframes with the size of each dataframe primarily determined by the limits\n# set by the Giantbomb API.\nload(\"./giantbomb_raw.Rds\")\n\n# If not running from scratch, we also load all other intermediate products \n# produced by the code in this document.\nif(!run_from_scratch) {\n    load(\"./giantbomb_intermediate_products.Rds\")\n}\n```\n\n## Create the Raw Dataframe\n\nThe Giantbomb data arrives as a list of dataframes, each retrieved from a single\nquery to the Giantbomb API. Each dataframe is a collection of game records. Our\nfirst step will be collapsing these into a single dataframe.\n\n```{r create_raw_df}\n# Retrieve the dataframe collection.\ndf_collection <- gb_raw_collection\n\n# Test for empty dataframes.\nrow_counts <- sapply(df_collection, nrow)\n\n# Drop dataframe(s) with 0 rows. This should only occur if we accidentally made\n# a query for a non-existent range of games (shouldn't happen but eh).\ndf_collection <- df_collection[!(row_counts == 0)]\n\n# Collapse the results to a single dataframe.\ngb_raw_df <- as.data.frame(rbind_all(df_collection), stringsAsFactors = FALSE)\n\n# Clean intermediate products from our workspace.\nrm(gb_raw_collection, df_collection, row_counts)\n\n# Make a fresh dataframe copy to work with in case we need to appeal to the\n# original.\ngb_df <- gb_raw_df\n```\n\n## Inspection\n\nIn this section we do some spot checking of the data to get a sense of the \ncontents of each column and to look for obvious fixes.\n\n```{r inspection}\n# We check the column types and notice an immediate issue.\ntypeof(gb_df$id)\ntypeof(gb_df$name)\ntypeof(gb_df$original_release_date)\ntypeof(gb_df$platforms)\n\n# Take a closer look at platforms.\nstr(gb_df$platforms[1])\n\n# Platforms is a column of dataframes - an undesirable complexity in our\n# dataframe that we'll need to address.\n\n# Take a closer look at the structure of the other columns.\nstr(gb_df[, -4])\n\n# And the print behavior of the title column.\nprint(head(gb_df$name, 15))\n\n# Get a sense for the number of levels in our features. \napply(gb_df[, -4], 2, function(x) length(unique(x)))\napply(gb_df[, -4], 2, function(x) sum(is.na(x)))\n```\n\nSome observations:\n\n* At least at first glance, the fields appear to be tidy and there are no \nobvious signs of duplication in our name field.\n\n* The platforms field needs to be collapsed into more standard columns before we\ncan really get a sense of what's in it.\n\n* The release date field has more information than we really want. We need to\nmake it a proper date-type column and extract year from it.\n\nWe do some quick global cleaning before we proceed to the dirty work.\n\n```{r first_pass_global_cleaning}\n# First things first, we need to simplify the platforms field. We extract the \n# long and short platform names for each game and then collapse them to single \n# fields.\nplat_df <- lapply(gb_df$platforms, function(x) {\n    platform_full <- paste(x$name, collapse = \"----\")\n    platform <- paste(x$abbreviation, collapse = \"----\")\n    \n    results <- data.frame(\n        \"platform_full\" = platform_full,\n        \"platform\" = platform,\n        stringsAsFactors = FALSE\n    )\n    \n    return(results)\n})\n\nplat_df <- bind_rows(plat_df)\n\n# We inspect the unique values in each column to assess if there are obvious NAs\n# we should clean out.\nunique_plats <- unlist(sapply(plat_df$platform, function(x) {\n    return(unlist(str_split(x, \"----\")))\n}, USE.NAMES = FALSE))\nunique_plats <- unique(unique_plats)\n\ntable(unique_plats)\n\n# The only obvious indicator of \"NA\" is the empty string \"\". We set these to NA\n# where we find them.\nplat_df$platform[plat_df$platform == \"\"] <- NA\nplat_df$platform_full[plat_df$platform_full == \"\"] <- NA\n\n# We update our game dataframe with the flat columns and drop the complex\n# column.\ngb_df <- select(gb_df, -platforms)\ngb_df <- cbind(gb_df, plat_df)\n\n# Clean-up the intermediate data products.\nrm(plat_df, unique_plats)\n\n# Column values (especially game titles) may look strange if the encoding is not\n# specified. We insure that they will be properly represented as UTF-8.\nEncoding(gb_df$name) <- \"UTF-8\"\nEncoding(gb_df$platform_full) <- \"UTF-8\"\nEncoding(gb_df$platform) <- \"UTF-8\"\n\n# Even though the Giantbomb data look very clean, we do take a few steps to \n# insure the fields avoid accidental junk (noting again that platform was\n# cleaned when we extracted it).\n\n# First we clean any non-space space characters, remove any leading/trailing\n# spaces, and replace double+ spaces with single spaces.\njunk_regex <- \"((?! )[[:space:]])|(\\\\((?! )[[:space:]]\\\\))\"\n\ngb_df$name <- gsub(junk_regex, \"\", gb_df$name, perl = TRUE)\ngb_df$name <- str_trim(gb_df$name)\ngb_df$name <- gsub(\"[[:space:]]{2,}\", \" \", gb_df$name)\n\nrm(junk_regex)\n```\n\n## Identify and Clean NAs, Set Types\n\nAt this point, we have columns that align with our target dataframe. We start \ngiving those columns a more thorough cleaning by standardizing how NAs are \nexpressed and insuring that column types are appropriate.\n\n```{r na_cleaning}\n# Checking for NAs and setting types is very straightforward as the data\n# quality is high for Giantbomb.\n\n## title ##\n# We simply inspect particularly short titles for NA patterns.\nshort_uniques <- unique(gb_df$name)\nshort_uniques <- short_uniques[nchar(short_uniques) < 4]\nsort(short_uniques)\n\n# There are some weird loking titles, but no obvious NAs.\nrm(short_uniques)\n\n## release date ##\n# Arrives as a character string. We start by converting this to a date type,\n# extracting year, and then simply inspect for unusual dates.\ngb_df$original_release_date <- ymd_hms(gb_df$original_release_date)\ngb_df$release_year <- year(gb_df$original_release_date)\n\ntable(gb_df$release_year)\n\n# The earliest game that could be considered a \"video\" game was released in 1950\n# and few games were released prior to the 1970s. We inspect the particularly \n# early games to see what is going.\ngb_df %>% \n    filter(release_year < 1950) %>% \n    select(name, release_year, platform_full) %>%\n    arrange(release_year)\n\n# It appears that a subset our games are not video games, but are instead \n# pinball games. We drop these from our data.\nis_pinball <- grepl(\"Pinball\", gb_df$platform_full)\nsum(is_pinball)\n\ngb_df <- gb_df[!is_pinball, ]\n\nrm(is_pinball)\n\n# We examine our early date games again.\ngb_df %>% \n    filter(release_year < 1965) %>% \n    select(name, release_year, platform_full) %>%\n    arrange(release_year)\n\n# All entries with release years before 1950 seem dubious. We set their date\n# fields to NA.\nis_early <- gb_df$release_year < 1950\nsum(is_early)\n\ngb_df$original_release_date[is_early] <- NA \ngb_df$release_year[is_early] <- NA\n\nrm(is_early)\n\n## Platform ##\n# We cleaned these when we extracted them.\n```\n\n## Inspecting for String Mispellings and Variations\n\nAgain, the Giantbomb data are in excellent condition. However, it definitely has\nsome explicit duplicate titles - certainly more than one would expect given how\nrare it is for different games to share the same name. We are also going to \ndouble check for game duplications resulting from game title\nmispellings/variations.\n\nDoing this type of cleaning completely requires some manual labor - at minimum\nwe would need to do enough manual cleaning to train a model for a more automated\nsolution. However, for the current project, we're going to automate what we can\nand - due to the sheer number of records - accept the risk of some duplications\n(and the loss of some games that happen to share the same title).\n\nWe adopt a collection of strategies to to allow us to automate the removal of as\nmany duplicates as possible.\n\n1. Creating a column version with standardized casing and common differences \nremoved (e.g., \"007: Nightfire\" v. \"007 - Nightfire\").\n\n2. First just examine unique values and not the entire record. In other words,\ndon't worry about record duplication yet - just word about similarities among\nall the unique values in a single field (e.g., resolve similar titles alone).\n\n3. Automate the pairing of values with potential matches based on a simple \nstring similarity index. This allows us to identify smaller collections of term \nv. match terms that we can process with more precise rules.\n\n4. Standardize how matched candidates are evaluated.  This allows us to specify \nup front what the criteria are for an automated \"match\" (i.e., a potential \nmispelling/variation) or \"mismatch\" (i.e., false positive based on similarity\nalone). If we ever choose to do the proper manual cleaning of values, this will \nalso minimize the manual work required.\n\n### Standardize Casing and Known Variations\n\nBased on experience with both the current data and titling in general, there are\na few common sources of variation we can attempt to account for up front.\n\n* _Subtitles_: Catalogers vary a great deal as to whether they used \" - \" or \n\": \" to indicate a subtitle. Sometimes unusual patterns (e.g., \" -text- \") are\nalso used to indicate subtitles, but we'll ignore these and simply take steps\nto make sure extra punctuation/spacing is ignored during our comparison stages.\n\n* _Hyphenation_: Whether or not a word is hyphenated (e.g., 2D v. 2-D) is also\na regular source of variation. Hyphenation is too flexible for us to catch\nall cases of correct or incorrect hyphenation, but we can at least standardize\nsome commonly abused cases.\n\n* _Common Shorthands_: We also keep an eye out for common shorthands that have\nvariabile forms (e.g., vs, vs., versus). Where we see these, we choose a single\nform to adopt.\n\n* _Spacing_: Although we cleaned up leading/trailing spaces, it is possible for\ncatalogers to inserted spaces into the title.\n\n* _Casing_: There are certaintly some games where the casing is part of the name\n(e.g., SiN). However, casing errors from human catalogers - especially for\nsituations where casing is non-standard - are likely to be a recurring source of\nerror. We'll compromise by having the comparison version of the column be all a\nsingle case.\n\n* _Roman and Written Numerals_: There are situations where coders chose to write\nnumbers as Roman numerals (e.g., 2 as \"II\") and to write short numbers as words\n(e.g., 1 as \"one\"). Where possible, we want to standardize how numbers are\npresented. Unfortunately, written numerals can be used in some unpredictable\nways, so we just focus on the Roman numeral to digit conversion.\n\n```{r variation_standardization}\n# Before we get started, we make new versions of the variables we'll be\n# tinkering with.\ngb_df$clean_name <- gb_df$name\ngb_df$clean_platform <- gb_df$platform\ngb_df$clean_platform_full <- gb_df$platform_full\n\n## Subtitles ##\n# Only really an issue for titles, so we ignore other fields during this\n# inspection.\n\n# Our ideal solution here is to convert either all \": \" to \" - \" or vice versa.\n# When picking between the two, it seems cleaner to convert all to \": \" (less\n# ambiguous) but we're more likely to succeed at converting all to \" - \"\n# (because we don't need to worry about identifying cases where \" - \" is not a\n# subtitle). We aim for the less ambiguous approach.\n\n# Key assumptions to this approach:\n# * \": \" is always used to indicate a subtitle.\n# * \" - \" is always used to indicate a subtitle.\n# * There are no incorrect uses of \":\" or \"-\" when indicating subtitles.\n\n# Secondary assumption:\n# * \": \" and \" - \" don't have unique uses in the same string.\n\n# \": \" used to indicate something other than a subtitle?\nhead(grep(\": \", unique(gb_df$clean_name), value = TRUE))\n# Result: None observed in the first few hundred entries.\n\n# \" - \" used to indicate something other than a subtitle?\nhead(grep(\" - \", unique(gb_df$clean_name), value = TRUE))\n# Result: Very few in titles and the only ones that were definitely problematic\n# to change were those in which a range of digits was being specified.\n\n# \" - \" used to indicate range of digits.\nlength(grep(\"[[:digit:]] - [[:digit:]]\", gb_df$clean_name, value = TRUE))\ngrep(\"[[:digit:]] - [[:digit:]]\", gb_df$clean_name, value = TRUE)\n# Result: We'll remove the spaces to disambiguate the problematic strings.\n\ntitles_to_fix <- c(\"Historyline: 1914 - 1918\", \n                   \"Mortyr (2093 - 1944)\",\n                   \"Super Yakyuudou '93 - 94 Nendo Data Kaiteiban\")\n\ngb_df$clean_name <- sapply(gb_df$clean_name, function(x) {\n    if(x %in% titles_to_fix) {\n        return(gsub(\" - \", \"-\", x))\n    } else {\n        return(x)\n    }\n}, USE.NAMES = FALSE)\n\nrm(titles_to_fix)\n\n# \"-\" used incorrectly or unusually?\nhead(grep(\"[^ ]- | -[^ ]\", unique(gb_df$clean_name), value = TRUE))\n# Result: Yes for titles. These fall into three cases - situations where \"-\" is\n# used to surround a word/phrase as a subtitle (e.g., \"animals -puppy-\"), where\n# \"-\" is doubled up, and where \"-\" just used wrong. We handle each.\n\n# Surround a word/phrase.\ngb_df$clean_name <- sapply(gb_df$clean_name, function(x) {\n    if(grepl(\"(^| )-[^ ].*-\", x)) {\n        x <- sub(\" -\", \": \", x)\n        x <- gsub(\"(-(?= |$))|(^-)\", \"\", x, perl = TRUE)\n        return(x)\n    } else {\n        return(x)\n    }\n}, USE.NAMES = FALSE)\n\n# Doubled up.\ngb_df$clean_name <- gsub(\"--\", \" - \", gb_df$clean_name)\n\n# Leading or trailing \"-\".\ngb_df$clean_name <- gsub(\" -(?=[^ ])\", \": \", gb_df$clean_name, perl = TRUE)\ngb_df$clean_name <- sapply(gb_df$clean_name, function(x) {\n    if(grepl(\"[^ ]- \", x, perl = TRUE)) {\n        return(gsub(\"- \", \": \", x))\n    } else {\n        return(x)\n    }\n}, USE.NAMES = FALSE)\n\n# \":\" used incorrectly or unusually?\ngrep(\" :|[^ ]:[^ ]\", unique(gb_df$clean_name), value = TRUE)\n# Result: Yes for titles. The problematic strings fall into three groups:\n# legitimate uses of \":\" with digits, incorrect uses of \":\" with characters, and\n# extra leading space \" : \".\n\ngb_df$clean_name <- sapply(gb_df$clean_name, function(x) {\n    if(grepl(paste0(\"([[:alnum:]]:[[:alpha:]])\",\n                    \"|([[:alpha:]]:[[:alnum:]])\",\n                    \"|( : )|(::)|( :[^ ])\"), x)) {\n        return(gsub(\"(:(?=[^ :]))|( : )|([ ]*::)|( :)\", \": \", x, perl = TRUE))\n    } else {\n        return(x)\n    }\n}, USE.NAMES = FALSE)\n\n# Converting \" - \" to \": \".\ngb_df$clean_name <- gsub(\" - \", \": \", gb_df$clean_name)\n\n## Hyphenation ##\n# This is also an issue we'll only really address in our title column. As noted\n# above, there are simply too many titles for us to correct all possible sources\n# of hyphenation. We simply scan for obvious variation issues and correct what\n# we can find.\nlength(grep(\"[^ ]-[^ ]\", gb_df$clean_name, value = TRUE))\nhead(grep(\"[^ ]-[^ ]\", gb_df$clean_name, value = TRUE), 100)\n\n# The most obvious problematic pattern is the shorthand for X-Dimensional (e.g.,\n# 2-D v. 2D v 2 D). We standardize these to remove the hyphenation.\ngb_df$clean_name <- sapply(gb_df$clean_name, function(x) {\n    if(grepl(\"([[:digit:]]-[Dd]( |$))\", x)) {\n        return(gsub(\"-(?=([Dd] )|([Dd]$))\", \"\", x, perl = TRUE))\n    } else {\n        return(x)\n    }\n}, USE.NAMES = FALSE)\n\n# Finally, we also have the problem of parens and brackets being used to either \n# add text or as an alternative subtitle mechanism. Since we can't distinguish \n# which is the case, we simply such parens/brackets where we observe them.\nbad_paren_index <- grepl(\"(^| )\\\\(.*?\\\\)(?= |$|;)\", gb_df$clean_name, \n                         perl = TRUE)\nbad_brack_index <- grepl(\"(^| )\\\\[.*?\\\\](?= |$|;)\", gb_df$clean_name, \n                         perl = TRUE)\n\ngb_df$clean_name <- sapply(1:length(gb_df$clean_name), function(x) {\n    current_name <- gb_df$clean_name[x]\n    \n    if(bad_paren_index[x]) {\n        current_name <- gsub(\"\\\\(|\\\\)\", \"\", current_name)\n    }\n    \n    if(bad_brack_index[x]) {\n        current_name <- gsub(\"\\\\[|\\\\]\", \"\", current_name)\n    }\n    \n    return(current_name)\n})\n\nrm(bad_paren_index, bad_brack_index)\n\n# In some cases, it is worth noting that parens were used to indicate working \n# titles of uncertain games. Where this occurs, we simply build a flag to \n# indicate uncertain title status and remove the added text from the name.\ngb_df$working_title <- grepl(\"working title\", gb_df$clean_name, \n                             ignore.case = TRUE)\ngb_df$clean_name <- gsub(\"working title\", \"\", gb_df$clean_name, \n                         ignore.case = TRUE)\n\n## Common Shorthands ##\n# We also try to standardize some other common patterns.\n# * vs, vs., versus\ngb_df$clean_name <- gsub(\"( vs )|( vs. )|( versus )\", \" vs \", gb_df$clean_name,\n                          ignore.case = TRUE)\n\n# * vol. , vol.\ngb_df$clean_name <- gsub(\"( vol )|( vol\\\\.)\", \" Volume \", gb_df$clean_name, \n                          ignore.case = TRUE)\n\n# * no.\ngb_df$clean_name <- gsub(\"( no\\\\. )|( no\\\\.)|( no [[:digit:]](?=(:|$)))\", \n                          \" Number \", \n                          gb_df$clean_name, ignore.case = TRUE, perl = TRUE)\n\n# * ep\ngb_df$clean_name <- gsub(\"( ep\\\\.)|( ep [[:digit:]])\", \" Number \",\n                          gb_df$clean_name, ignore.case = TRUE)\n\n# * &\ngb_df$clean_name <- gsub(\"[^[:punct:]]&[^[:punct:]]\", \" and \", \n                         gb_df$clean_name)\n\n## Spacing ##\n# This is one of our more straightforward cleaning steps. We simply don't allow\n# our strings to have more than a single space in them to remove accidental\n# multi-space sequences.\ngb_df$clean_name <- gsub(\"[ ]{2,}\", \" \", gb_df$clean_name)\ngb_df$clean_platform <- gsub(\"[ ]{2,}\", \" \", gb_df$clean_platform)\ngb_df$clean_platform_full <- gsub(\"[ ]{2,}\", \" \", gb_df$clean_platform_full)\n\n# And we insure that we introduced no new leading/trailing spaces with all our\n# fixing.\ngb_df$clean_name <- str_trim(gb_df$clean_name)\ngb_df$clean_platform <- str_trim(gb_df$clean_platform)\ngb_df$clean_platform_full <- str_trim(gb_df$clean_platform_full)\n\n## Casing ##\n# Finally, we make the decision to ignore casing for our observed values and we\n# enforce standard casing behavior on all our target fields. This is a jump from\n# the title cleaning we've been doing and it breaks potentially desirable\n# formatting. We do this work in a new column with the understanding that we'll\n# need to eventually need to choose a desired \"natural\" casing for each value.\ngb_df$flat_name <- str_to_lower(gb_df$clean_name)\ngb_df$flat_platform <- str_to_lower(gb_df$clean_platform)\ngb_df$flat_platform_full <- str_to_lower(gb_df$clean_platform_full)\n\n## Roman and Written Numerals ##\n# We convert all characters chunks likely to be Roman numerals. The Roman\n# numeral conversion will result in some false positives (e.g., puppy and i\n# becomes puppy and 1), but we accept these for the purpose of string matching.\n# We restrict this work to titles as the choice of a number format is more\n# likely to be intentional for publishers, developers, and platforms.\n\n# Roman numeral conversion. Roman numerals almost always occur at the end of a\n# title/subtitle, so we minimize false positives by only looking for matches \n# indicating the end of a major title portion.\nnumeral_range <- c(1:50)\nfor(number in numeral_range) {\n    roman <- as.roman(number)\n    roman_regex <- paste0(\"(?<=[^[:alnum:]]|^)\", \n                          str_to_lower(roman), \n                          \"(?=[^[:alnum:]]|$)\")\n    gb_df$flat_name <- gsub(roman_regex, as.character(number), \n                            gb_df$flat_name, \n                            perl = TRUE)\n}\n\nrm(number, numeral_range, roman, roman_regex)\n\n# Written numeral conversion. We create a vector of common words and a matching\n# vector of their numeric form.\nwritten_numerals <- c(\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\",\n                      \"seven\", \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\",\n                      \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\",\n                      \"eighteen\", \"nineteen\", \"twenty\", \"thirty\", \"forty\", \n                      \"fourty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\")\nnumeral_range <- c(0:20, 30, 40, 40, 50, 60, 70, 80, 90)\nfor(index in 1:length(numeral_range)) {\n    written_regex <- paste0(\"(?<=[^[:alnum:]]|^)\", \n                            written_numerals[index], \n                            \"(?=[^[:alnum:]]|$)\")\n    gb_df$flat_name <- gsub(written_regex, numeral_range[index], \n                            gb_df$flat_name, \n                            perl = TRUE)\n}\n\nrm(written_numerals, numeral_range, index, written_regex)\n\n```\n### Identify Variation/Mispelling Candidates\n\n**NOTE**: The `id_variations_from_scratch` global gets assessed in this section.\nIf set to `TRUE`, this section will take up to several hours to identify \ncandidate associations and then (in the next section) resolve the candidate \nassociations.\n\n```{r id_variation_candidates}\n# This section handles identifying candidates for variations and mispellings. It\n# is recommended that you only trigger this section if you are certain it is \n# necessary and know what you are doing as it is time-consuming.\nif(run_from_scratch) {\n    # First we look for variations/mispellings in our titles. This is the most\n    # time-consuming of the variation processing. We save some processing by\n    # focusing only on unique values (removing obvious duplicates from\n    # consideration).\n    unique_titles <- unique(gb_df$flat_name)\n    \n    title_matches <- fuzzy_match_all(unique_titles, max_dist = 0.1,\n                                     skip_pure_digit = TRUE, \n                                     min_test_length = 3,\n                                     assume_unique = TRUE, \n                                     remove_matches = TRUE)\n\n    # Remove intermediate data products.\n    rm(unique_titles)\n}\n```\n\n### Process Variation/Mispelling Candidates\n\nWe now have a set of lists that identify terms that appear to be reasonable \ncandidates for having variations/mispellings along with the associated candidate\nvariations/mispellings. We use a helper function to walk-through our target \nsource--match sets and apply some basic logic to auto-assess for match validity.\nSee the definition for the `resolve_match` to observe the rules determing what\ncounts as a match or not.\n\n**NOTE**: The `resolve_variations_from_scratch` global gets assessed in this\nsection. If set to `TRUE`, this section can take some time to complete.\n\n```{r process_variation_candidates}\n# This section handles processing candidates for variations and mispellings. It\n# is recommended that you only trigger this section if you are certain it is \n# necessary and know what you are doing as it is time-consuming.\nif(run_from_scratch) {\n    # We run our auto-resolver on each of the collections.\n    auto_title_matches <- resolve_all_match_sets(title_matches)\n}\n```\n\n### Clean Identified Variation/Mispelling Pairs\n\nAt this point we've produced some objects that could either be subjected to \nmanual processing (to resolve uncertain candidate matches) or which can be used\nto guide standardization of variation/mispelling collections as-is. For this \nproject, we simply use the current auto-matched results and acknowledge that \nwe've likely missed a few matches.\n\nIt's worth noting that we've done our matching with a highly stripped down \nversion of our values (certain punctuation and casing removed). We'll use the \nresults of matching these values to replace our richer-formatting titles as \nwell, but we'll retain the original raw versions to allow us to spot check for \nerrors if the need arises.\n\n```{r apply_variation_candidates}\nif(run_from_scratch) {\n    ## titles ##\n    fix_titles <- auto_title_matches$match_set_list\n    fix_titles <- fix_titles[auto_title_matches$auto_accept_index]\n    \n    clean_gb_df <- fix_all_match_sets(fix_titles, gb_df, \n                                      \"clean_name\", \"flat_name\")\n    \n    ## cleanup ##\n    rm(fix_titles)\n}\n```\n\n## Roll Up to One Record per Game\n\nGiantbomb is intended to be a one-record per game database, but we've found a \nfew duplicates tucked into the otherwise lovely data. We roll up on title to \nremove these duplicates.\n\nWe'll allow our other fields to initially become more complex, concatenating \nthem together. During this concatenation, we'll also sort the elements and \nremove duplicates in the complex fields.\n\n```{r roll_up}\nif(run_from_scratch) {\n    # And another version by title alone.\n    g_df <- clean_gb_df %>%\n        group_by(flat_title = flat_name) %>%\n        summarise(\n            title = sort_elements(clean_name),\n            platform = sort_elements(clean_platform),\n            min_year = min(release_year, na.rm = TRUE),\n            max_year = max(release_year, na.rm = TRUE),\n            release_year = sort_elements(release_year),\n            plat_test = sort_elements(flat_platform, dedup = FALSE,\n                                      cf_split = \"~~~~\"),\n            ry_test = sort_elements(release_year, dedup = FALSE,\n                                    cf_split = \"~~~~\"),\n            flat_platform = sort_elements(flat_platform),\n            raw_title = sort_elements(name),\n            id = sort_elements(id)\n        ) %>%\n        ungroup() %>%\n        mutate(max_min_gap = max_year - min_year,\n               njoins = nchar(gsub(\"[^-]\", \"\", release_year)) / 4)\n    \n    # We inspect the list for instances where the roll-up seems like it may be\n    # problematic: roll-ups that pulled together records with very different\n    # release years.\n    table(g_df$max_min_gap, useNA = \"ifany\")\n}\n```\n\n## Finalize the Dataframe\n\nAt this point, we have all the pieces we want for our merge-ready dataframe. We\npull out the key columns and save the result.\n\n```{r merge_ready_df}\n# Select our target columns and create the merge-ready dataframe.\ngb_merge_df <- g_df %>%\n    select(\n        # Core features.\n        title, platform, first_release_year = min_year,\n        # Merge friendly versions of character features.\n        flat_title, flat_platform,\n        # Additional useful Giantbomb features.\n        id, raw_title, all_release_year = release_year)\n\n# Add a prefix so that columns are not lost accidentally during the merge.\nnames(gb_merge_df) <- paste0(\"gb_\", names(gb_merge_df))\n\n# If run from scratch, we save the key intermediate and final data products.\nif(run_from_scratch) {\n    save(title_matches, auto_title_matches, g_df,\n         file = \"./giantbomb_intermediate_products.Rds\")\n    \n    save(gb_merge_df, file = \"./gb_merge_df.Rds\")\n}\n```\n",
    "created" : 1464294192173.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1277117988",
    "id" : "91A3E870",
    "lastKnownWriteTime" : 1464296437,
    "path" : "C:/Projects/vgsample/vignettes/giantbomb_data_cleaning.Rmd",
    "project_path" : "vignettes/giantbomb_data_cleaning.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "type" : "r_markdown"
}